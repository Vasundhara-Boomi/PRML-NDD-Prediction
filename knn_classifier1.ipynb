{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasundhara-Boomi/PRML-NDD-Prediction/blob/main/knn_classifier1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTMpAhvJpZR8",
        "outputId": "c1401041-02d2-4b5c-92ad-3b41c2501332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tslearnNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Downloading tslearn-0.6.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tslearn) (1.24.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tslearn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tslearn) (1.3.2)\n",
            "Requirement already satisfied: numba in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tslearn) (0.59.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tslearn) (1.4.0)\n",
            "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from numba->tslearn) (0.42.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn->tslearn) (3.2.0)\n",
            "Downloading tslearn-0.6.3-py3-none-any.whl (374 kB)\n",
            "   ---------------------------------------- 374.4/374.4 kB 3.9 MB/s eta 0:00:00\n",
            "Installing collected packages: tslearn\n",
            "Successfully installed tslearn-0.6.3\n"
          ]
        }
      ],
      "source": [
        "%pip install tslearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJqlFWJUpZSD",
        "outputId": "021d57c7-03ae-46b7-ca23-1d88382541f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.1.1)\n",
            "Requirement already satisfied: absl-py in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (2.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (1.24.3)\n",
            "Requirement already satisfied: rich in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (12.5.1)\n",
            "Requirement already satisfied: namex in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (3.10.0)\n",
            "Requirement already satisfied: optree in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from optree->keras) (4.10.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras) (2.13.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q_QDo44pZSE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkrK_GvupZSF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.model_selection import LeaveOneOut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bR-fMOBppZSG"
      },
      "outputs": [],
      "source": [
        "# Load the transformed data\n",
        "transformed_ct = pd.read_csv(r'transformed_data\\transformed_ct.csv')\n",
        "transformed_pd = pd.read_csv(r'transformed_data\\transformed_pd.csv')\n",
        "transformed_ht = pd.read_csv(r'transformed_data\\transformed_ht.csv')\n",
        "transformed_als = pd.read_csv(r'transformed_data\\transformed_als.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd463pPFpZSH"
      },
      "outputs": [],
      "source": [
        "# Add a column for labels\n",
        "transformed_ct['label'] = 'control'\n",
        "transformed_pd['label'] = 'parkinson'\n",
        "transformed_ht['label'] = 'huntington'\n",
        "transformed_als['label'] = 'als'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGn0yzeZpZSH"
      },
      "outputs": [],
      "source": [
        "# Combine all data into a single DataFrame\n",
        "data = pd.concat([transformed_ct, transformed_pd, transformed_ht, transformed_als], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yo_EKUipZSI",
        "outputId": "c2b7ef11-842b-499e-8558-4ff8192fc291"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Elapsed Time(s)Min</th>\n",
              "      <th>Elapsed Time(s)Max</th>\n",
              "      <th>Elapsed Time(s)Std</th>\n",
              "      <th>Elapsed Time(s)Med</th>\n",
              "      <th>Elapsed Time(s)Avg</th>\n",
              "      <th>Elapsed Time(s)Skewness</th>\n",
              "      <th>Elapsed Time(s)Kurtosis</th>\n",
              "      <th>Left Stride Interval(s)Min</th>\n",
              "      <th>Left Stride Interval(s)Max</th>\n",
              "      <th>...</th>\n",
              "      <th>Double Support Interval(s)Skewness</th>\n",
              "      <th>Double Support Interval(s)Kurtosis</th>\n",
              "      <th>Double Support Interval(%)Min</th>\n",
              "      <th>Double Support Interval(%)Max</th>\n",
              "      <th>Double Support Interval(%)Std</th>\n",
              "      <th>Double Support Interval(%)Med</th>\n",
              "      <th>Double Support Interval(%)Avg</th>\n",
              "      <th>Double Support Interval(%)Skewness</th>\n",
              "      <th>Double Support Interval(%)Kurtosis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>21.9300</td>\n",
              "      <td>298.6000</td>\n",
              "      <td>80.541475</td>\n",
              "      <td>159.63670</td>\n",
              "      <td>159.676873</td>\n",
              "      <td>0.007791</td>\n",
              "      <td>-1.205423</td>\n",
              "      <td>0.9633</td>\n",
              "      <td>1.3967</td>\n",
              "      <td>...</td>\n",
              "      <td>1.846643</td>\n",
              "      <td>7.133888</td>\n",
              "      <td>26.69</td>\n",
              "      <td>46.03</td>\n",
              "      <td>2.582514</td>\n",
              "      <td>31.830</td>\n",
              "      <td>32.048185</td>\n",
              "      <td>1.657463</td>\n",
              "      <td>6.628575</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>22.0600</td>\n",
              "      <td>298.7500</td>\n",
              "      <td>80.301624</td>\n",
              "      <td>159.92330</td>\n",
              "      <td>160.034960</td>\n",
              "      <td>0.003471</td>\n",
              "      <td>-1.199675</td>\n",
              "      <td>0.9300</td>\n",
              "      <td>1.3533</td>\n",
              "      <td>...</td>\n",
              "      <td>6.941808</td>\n",
              "      <td>70.516428</td>\n",
              "      <td>23.18</td>\n",
              "      <td>46.80</td>\n",
              "      <td>1.989210</td>\n",
              "      <td>26.170</td>\n",
              "      <td>26.510578</td>\n",
              "      <td>5.874844</td>\n",
              "      <td>51.107931</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>21.6100</td>\n",
              "      <td>299.0567</td>\n",
              "      <td>80.423591</td>\n",
              "      <td>160.76000</td>\n",
              "      <td>160.275018</td>\n",
              "      <td>-0.002409</td>\n",
              "      <td>-1.202074</td>\n",
              "      <td>0.9667</td>\n",
              "      <td>1.3767</td>\n",
              "      <td>...</td>\n",
              "      <td>3.291091</td>\n",
              "      <td>18.503456</td>\n",
              "      <td>27.71</td>\n",
              "      <td>41.74</td>\n",
              "      <td>1.920116</td>\n",
              "      <td>31.310</td>\n",
              "      <td>31.494610</td>\n",
              "      <td>1.796461</td>\n",
              "      <td>6.547346</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>21.8933</td>\n",
              "      <td>299.7633</td>\n",
              "      <td>80.529795</td>\n",
              "      <td>160.14830</td>\n",
              "      <td>160.156720</td>\n",
              "      <td>0.005247</td>\n",
              "      <td>-1.193897</td>\n",
              "      <td>1.0033</td>\n",
              "      <td>2.0233</td>\n",
              "      <td>...</td>\n",
              "      <td>9.383892</td>\n",
              "      <td>109.145808</td>\n",
              "      <td>23.15</td>\n",
              "      <td>56.67</td>\n",
              "      <td>2.977208</td>\n",
              "      <td>26.180</td>\n",
              "      <td>26.703115</td>\n",
              "      <td>5.819219</td>\n",
              "      <td>47.517179</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>22.3600</td>\n",
              "      <td>299.4167</td>\n",
              "      <td>80.219752</td>\n",
              "      <td>159.71000</td>\n",
              "      <td>160.227956</td>\n",
              "      <td>0.012561</td>\n",
              "      <td>-1.190490</td>\n",
              "      <td>1.0300</td>\n",
              "      <td>1.2967</td>\n",
              "      <td>...</td>\n",
              "      <td>2.858954</td>\n",
              "      <td>16.734192</td>\n",
              "      <td>21.45</td>\n",
              "      <td>42.16</td>\n",
              "      <td>2.461296</td>\n",
              "      <td>25.860</td>\n",
              "      <td>26.391873</td>\n",
              "      <td>2.645490</td>\n",
              "      <td>12.970039</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>8</td>\n",
              "      <td>21.9533</td>\n",
              "      <td>288.9133</td>\n",
              "      <td>78.506061</td>\n",
              "      <td>153.10330</td>\n",
              "      <td>156.746292</td>\n",
              "      <td>-0.003560</td>\n",
              "      <td>-1.239587</td>\n",
              "      <td>1.1733</td>\n",
              "      <td>9.1833</td>\n",
              "      <td>...</td>\n",
              "      <td>5.154047</td>\n",
              "      <td>49.777404</td>\n",
              "      <td>25.00</td>\n",
              "      <td>134.31</td>\n",
              "      <td>47.483061</td>\n",
              "      <td>33.060</td>\n",
              "      <td>73.440439</td>\n",
              "      <td>0.221811</td>\n",
              "      <td>-1.928994</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>9</td>\n",
              "      <td>22.7167</td>\n",
              "      <td>298.4100</td>\n",
              "      <td>80.233487</td>\n",
              "      <td>161.48835</td>\n",
              "      <td>160.529298</td>\n",
              "      <td>0.003958</td>\n",
              "      <td>-1.201741</td>\n",
              "      <td>1.4233</td>\n",
              "      <td>2.1700</td>\n",
              "      <td>...</td>\n",
              "      <td>3.286439</td>\n",
              "      <td>16.668301</td>\n",
              "      <td>35.93</td>\n",
              "      <td>67.28</td>\n",
              "      <td>4.369722</td>\n",
              "      <td>43.495</td>\n",
              "      <td>44.058977</td>\n",
              "      <td>2.022438</td>\n",
              "      <td>7.497516</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>10</td>\n",
              "      <td>23.5267</td>\n",
              "      <td>299.4433</td>\n",
              "      <td>79.445782</td>\n",
              "      <td>159.00000</td>\n",
              "      <td>160.555286</td>\n",
              "      <td>0.022279</td>\n",
              "      <td>-1.179486</td>\n",
              "      <td>1.5067</td>\n",
              "      <td>2.2733</td>\n",
              "      <td>...</td>\n",
              "      <td>1.302906</td>\n",
              "      <td>-0.176652</td>\n",
              "      <td>23.08</td>\n",
              "      <td>161.44</td>\n",
              "      <td>43.788066</td>\n",
              "      <td>42.910</td>\n",
              "      <td>64.953711</td>\n",
              "      <td>1.311714</td>\n",
              "      <td>-0.198004</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>11</td>\n",
              "      <td>22.8900</td>\n",
              "      <td>299.0233</td>\n",
              "      <td>80.484751</td>\n",
              "      <td>158.15335</td>\n",
              "      <td>159.315691</td>\n",
              "      <td>0.026569</td>\n",
              "      <td>-1.205942</td>\n",
              "      <td>1.0567</td>\n",
              "      <td>1.6533</td>\n",
              "      <td>...</td>\n",
              "      <td>2.086797</td>\n",
              "      <td>6.995220</td>\n",
              "      <td>23.19</td>\n",
              "      <td>53.63</td>\n",
              "      <td>2.712919</td>\n",
              "      <td>30.210</td>\n",
              "      <td>30.731422</td>\n",
              "      <td>3.042503</td>\n",
              "      <td>21.384431</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>12</td>\n",
              "      <td>22.6033</td>\n",
              "      <td>299.0500</td>\n",
              "      <td>80.820757</td>\n",
              "      <td>154.89500</td>\n",
              "      <td>156.945927</td>\n",
              "      <td>0.055421</td>\n",
              "      <td>-1.207686</td>\n",
              "      <td>1.0300</td>\n",
              "      <td>1.6467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.291030</td>\n",
              "      <td>1.952326</td>\n",
              "      <td>23.08</td>\n",
              "      <td>40.50</td>\n",
              "      <td>1.596464</td>\n",
              "      <td>28.400</td>\n",
              "      <td>28.379764</td>\n",
              "      <td>1.955008</td>\n",
              "      <td>15.211556</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 93 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  Elapsed Time(s)Min  Elapsed Time(s)Max  Elapsed Time(s)Std  \\\n",
              "0            0             21.9300            298.6000           80.541475   \n",
              "1            1             22.0600            298.7500           80.301624   \n",
              "2            2             21.6100            299.0567           80.423591   \n",
              "3            3             21.8933            299.7633           80.529795   \n",
              "4            4             22.3600            299.4167           80.219752   \n",
              "..         ...                 ...                 ...                 ...   \n",
              "59           8             21.9533            288.9133           78.506061   \n",
              "60           9             22.7167            298.4100           80.233487   \n",
              "61          10             23.5267            299.4433           79.445782   \n",
              "62          11             22.8900            299.0233           80.484751   \n",
              "63          12             22.6033            299.0500           80.820757   \n",
              "\n",
              "    Elapsed Time(s)Med  Elapsed Time(s)Avg  Elapsed Time(s)Skewness  \\\n",
              "0            159.63670          159.676873                 0.007791   \n",
              "1            159.92330          160.034960                 0.003471   \n",
              "2            160.76000          160.275018                -0.002409   \n",
              "3            160.14830          160.156720                 0.005247   \n",
              "4            159.71000          160.227956                 0.012561   \n",
              "..                 ...                 ...                      ...   \n",
              "59           153.10330          156.746292                -0.003560   \n",
              "60           161.48835          160.529298                 0.003958   \n",
              "61           159.00000          160.555286                 0.022279   \n",
              "62           158.15335          159.315691                 0.026569   \n",
              "63           154.89500          156.945927                 0.055421   \n",
              "\n",
              "    Elapsed Time(s)Kurtosis  Left Stride Interval(s)Min  \\\n",
              "0                 -1.205423                      0.9633   \n",
              "1                 -1.199675                      0.9300   \n",
              "2                 -1.202074                      0.9667   \n",
              "3                 -1.193897                      1.0033   \n",
              "4                 -1.190490                      1.0300   \n",
              "..                      ...                         ...   \n",
              "59                -1.239587                      1.1733   \n",
              "60                -1.201741                      1.4233   \n",
              "61                -1.179486                      1.5067   \n",
              "62                -1.205942                      1.0567   \n",
              "63                -1.207686                      1.0300   \n",
              "\n",
              "    Left Stride Interval(s)Max  ...  Double Support Interval(s)Skewness  \\\n",
              "0                       1.3967  ...                            1.846643   \n",
              "1                       1.3533  ...                            6.941808   \n",
              "2                       1.3767  ...                            3.291091   \n",
              "3                       2.0233  ...                            9.383892   \n",
              "4                       1.2967  ...                            2.858954   \n",
              "..                         ...  ...                                 ...   \n",
              "59                      9.1833  ...                            5.154047   \n",
              "60                      2.1700  ...                            3.286439   \n",
              "61                      2.2733  ...                            1.302906   \n",
              "62                      1.6533  ...                            2.086797   \n",
              "63                      1.6467  ...                            0.291030   \n",
              "\n",
              "    Double Support Interval(s)Kurtosis  Double Support Interval(%)Min  \\\n",
              "0                             7.133888                          26.69   \n",
              "1                            70.516428                          23.18   \n",
              "2                            18.503456                          27.71   \n",
              "3                           109.145808                          23.15   \n",
              "4                            16.734192                          21.45   \n",
              "..                                 ...                            ...   \n",
              "59                           49.777404                          25.00   \n",
              "60                           16.668301                          35.93   \n",
              "61                           -0.176652                          23.08   \n",
              "62                            6.995220                          23.19   \n",
              "63                            1.952326                          23.08   \n",
              "\n",
              "    Double Support Interval(%)Max  Double Support Interval(%)Std  \\\n",
              "0                           46.03                       2.582514   \n",
              "1                           46.80                       1.989210   \n",
              "2                           41.74                       1.920116   \n",
              "3                           56.67                       2.977208   \n",
              "4                           42.16                       2.461296   \n",
              "..                            ...                            ...   \n",
              "59                         134.31                      47.483061   \n",
              "60                          67.28                       4.369722   \n",
              "61                         161.44                      43.788066   \n",
              "62                          53.63                       2.712919   \n",
              "63                          40.50                       1.596464   \n",
              "\n",
              "    Double Support Interval(%)Med  Double Support Interval(%)Avg  \\\n",
              "0                          31.830                      32.048185   \n",
              "1                          26.170                      26.510578   \n",
              "2                          31.310                      31.494610   \n",
              "3                          26.180                      26.703115   \n",
              "4                          25.860                      26.391873   \n",
              "..                            ...                            ...   \n",
              "59                         33.060                      73.440439   \n",
              "60                         43.495                      44.058977   \n",
              "61                         42.910                      64.953711   \n",
              "62                         30.210                      30.731422   \n",
              "63                         28.400                      28.379764   \n",
              "\n",
              "    Double Support Interval(%)Skewness  Double Support Interval(%)Kurtosis  \\\n",
              "0                             1.657463                            6.628575   \n",
              "1                             5.874844                           51.107931   \n",
              "2                             1.796461                            6.547346   \n",
              "3                             5.819219                           47.517179   \n",
              "4                             2.645490                           12.970039   \n",
              "..                                 ...                                 ...   \n",
              "59                            0.221811                           -1.928994   \n",
              "60                            2.022438                            7.497516   \n",
              "61                            1.311714                           -0.198004   \n",
              "62                            3.042503                           21.384431   \n",
              "63                            1.955008                           15.211556   \n",
              "\n",
              "      label  \n",
              "0   control  \n",
              "1   control  \n",
              "2   control  \n",
              "3   control  \n",
              "4   control  \n",
              "..      ...  \n",
              "59      als  \n",
              "60      als  \n",
              "61      als  \n",
              "62      als  \n",
              "63      als  \n",
              "\n",
              "[64 rows x 93 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcYPfUT0pZSJ"
      },
      "outputs": [],
      "source": [
        "# Drop the first column which is the index column from the CSV files\n",
        "data = data.drop(columns=data.columns[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjAfspNipZSJ",
        "outputId": "fd24abf0-78c0-4d8f-fca8-4cc573dc44a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elapsed Time(s)Min</th>\n",
              "      <th>Elapsed Time(s)Max</th>\n",
              "      <th>Elapsed Time(s)Std</th>\n",
              "      <th>Elapsed Time(s)Med</th>\n",
              "      <th>Elapsed Time(s)Avg</th>\n",
              "      <th>Elapsed Time(s)Skewness</th>\n",
              "      <th>Elapsed Time(s)Kurtosis</th>\n",
              "      <th>Left Stride Interval(s)Min</th>\n",
              "      <th>Left Stride Interval(s)Max</th>\n",
              "      <th>Left Stride Interval(s)Std</th>\n",
              "      <th>...</th>\n",
              "      <th>Double Support Interval(s)Skewness</th>\n",
              "      <th>Double Support Interval(s)Kurtosis</th>\n",
              "      <th>Double Support Interval(%)Min</th>\n",
              "      <th>Double Support Interval(%)Max</th>\n",
              "      <th>Double Support Interval(%)Std</th>\n",
              "      <th>Double Support Interval(%)Med</th>\n",
              "      <th>Double Support Interval(%)Avg</th>\n",
              "      <th>Double Support Interval(%)Skewness</th>\n",
              "      <th>Double Support Interval(%)Kurtosis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21.9300</td>\n",
              "      <td>298.6000</td>\n",
              "      <td>80.541475</td>\n",
              "      <td>159.63670</td>\n",
              "      <td>159.676873</td>\n",
              "      <td>0.007791</td>\n",
              "      <td>-1.205423</td>\n",
              "      <td>0.9633</td>\n",
              "      <td>1.3967</td>\n",
              "      <td>0.040895</td>\n",
              "      <td>...</td>\n",
              "      <td>1.846643</td>\n",
              "      <td>7.133888</td>\n",
              "      <td>26.69</td>\n",
              "      <td>46.03</td>\n",
              "      <td>2.582514</td>\n",
              "      <td>31.830</td>\n",
              "      <td>32.048185</td>\n",
              "      <td>1.657463</td>\n",
              "      <td>6.628575</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22.0600</td>\n",
              "      <td>298.7500</td>\n",
              "      <td>80.301624</td>\n",
              "      <td>159.92330</td>\n",
              "      <td>160.034960</td>\n",
              "      <td>0.003471</td>\n",
              "      <td>-1.199675</td>\n",
              "      <td>0.9300</td>\n",
              "      <td>1.3533</td>\n",
              "      <td>0.041952</td>\n",
              "      <td>...</td>\n",
              "      <td>6.941808</td>\n",
              "      <td>70.516428</td>\n",
              "      <td>23.18</td>\n",
              "      <td>46.80</td>\n",
              "      <td>1.989210</td>\n",
              "      <td>26.170</td>\n",
              "      <td>26.510578</td>\n",
              "      <td>5.874844</td>\n",
              "      <td>51.107931</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21.6100</td>\n",
              "      <td>299.0567</td>\n",
              "      <td>80.423591</td>\n",
              "      <td>160.76000</td>\n",
              "      <td>160.275018</td>\n",
              "      <td>-0.002409</td>\n",
              "      <td>-1.202074</td>\n",
              "      <td>0.9667</td>\n",
              "      <td>1.3767</td>\n",
              "      <td>0.036877</td>\n",
              "      <td>...</td>\n",
              "      <td>3.291091</td>\n",
              "      <td>18.503456</td>\n",
              "      <td>27.71</td>\n",
              "      <td>41.74</td>\n",
              "      <td>1.920116</td>\n",
              "      <td>31.310</td>\n",
              "      <td>31.494610</td>\n",
              "      <td>1.796461</td>\n",
              "      <td>6.547346</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.8933</td>\n",
              "      <td>299.7633</td>\n",
              "      <td>80.529795</td>\n",
              "      <td>160.14830</td>\n",
              "      <td>160.156720</td>\n",
              "      <td>0.005247</td>\n",
              "      <td>-1.193897</td>\n",
              "      <td>1.0033</td>\n",
              "      <td>2.0233</td>\n",
              "      <td>0.074304</td>\n",
              "      <td>...</td>\n",
              "      <td>9.383892</td>\n",
              "      <td>109.145808</td>\n",
              "      <td>23.15</td>\n",
              "      <td>56.67</td>\n",
              "      <td>2.977208</td>\n",
              "      <td>26.180</td>\n",
              "      <td>26.703115</td>\n",
              "      <td>5.819219</td>\n",
              "      <td>47.517179</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.3600</td>\n",
              "      <td>299.4167</td>\n",
              "      <td>80.219752</td>\n",
              "      <td>159.71000</td>\n",
              "      <td>160.227956</td>\n",
              "      <td>0.012561</td>\n",
              "      <td>-1.190490</td>\n",
              "      <td>1.0300</td>\n",
              "      <td>1.2967</td>\n",
              "      <td>0.038959</td>\n",
              "      <td>...</td>\n",
              "      <td>2.858954</td>\n",
              "      <td>16.734192</td>\n",
              "      <td>21.45</td>\n",
              "      <td>42.16</td>\n",
              "      <td>2.461296</td>\n",
              "      <td>25.860</td>\n",
              "      <td>26.391873</td>\n",
              "      <td>2.645490</td>\n",
              "      <td>12.970039</td>\n",
              "      <td>control</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>21.9533</td>\n",
              "      <td>288.9133</td>\n",
              "      <td>78.506061</td>\n",
              "      <td>153.10330</td>\n",
              "      <td>156.746292</td>\n",
              "      <td>-0.003560</td>\n",
              "      <td>-1.239587</td>\n",
              "      <td>1.1733</td>\n",
              "      <td>9.1833</td>\n",
              "      <td>0.561663</td>\n",
              "      <td>...</td>\n",
              "      <td>5.154047</td>\n",
              "      <td>49.777404</td>\n",
              "      <td>25.00</td>\n",
              "      <td>134.31</td>\n",
              "      <td>47.483061</td>\n",
              "      <td>33.060</td>\n",
              "      <td>73.440439</td>\n",
              "      <td>0.221811</td>\n",
              "      <td>-1.928994</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>22.7167</td>\n",
              "      <td>298.4100</td>\n",
              "      <td>80.233487</td>\n",
              "      <td>161.48835</td>\n",
              "      <td>160.529298</td>\n",
              "      <td>0.003958</td>\n",
              "      <td>-1.201741</td>\n",
              "      <td>1.4233</td>\n",
              "      <td>2.1700</td>\n",
              "      <td>0.102321</td>\n",
              "      <td>...</td>\n",
              "      <td>3.286439</td>\n",
              "      <td>16.668301</td>\n",
              "      <td>35.93</td>\n",
              "      <td>67.28</td>\n",
              "      <td>4.369722</td>\n",
              "      <td>43.495</td>\n",
              "      <td>44.058977</td>\n",
              "      <td>2.022438</td>\n",
              "      <td>7.497516</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>23.5267</td>\n",
              "      <td>299.4433</td>\n",
              "      <td>79.445782</td>\n",
              "      <td>159.00000</td>\n",
              "      <td>160.555286</td>\n",
              "      <td>0.022279</td>\n",
              "      <td>-1.179486</td>\n",
              "      <td>1.5067</td>\n",
              "      <td>2.2733</td>\n",
              "      <td>0.129713</td>\n",
              "      <td>...</td>\n",
              "      <td>1.302906</td>\n",
              "      <td>-0.176652</td>\n",
              "      <td>23.08</td>\n",
              "      <td>161.44</td>\n",
              "      <td>43.788066</td>\n",
              "      <td>42.910</td>\n",
              "      <td>64.953711</td>\n",
              "      <td>1.311714</td>\n",
              "      <td>-0.198004</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>22.8900</td>\n",
              "      <td>299.0233</td>\n",
              "      <td>80.484751</td>\n",
              "      <td>158.15335</td>\n",
              "      <td>159.315691</td>\n",
              "      <td>0.026569</td>\n",
              "      <td>-1.205942</td>\n",
              "      <td>1.0567</td>\n",
              "      <td>1.6533</td>\n",
              "      <td>0.073385</td>\n",
              "      <td>...</td>\n",
              "      <td>2.086797</td>\n",
              "      <td>6.995220</td>\n",
              "      <td>23.19</td>\n",
              "      <td>53.63</td>\n",
              "      <td>2.712919</td>\n",
              "      <td>30.210</td>\n",
              "      <td>30.731422</td>\n",
              "      <td>3.042503</td>\n",
              "      <td>21.384431</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>22.6033</td>\n",
              "      <td>299.0500</td>\n",
              "      <td>80.820757</td>\n",
              "      <td>154.89500</td>\n",
              "      <td>156.945927</td>\n",
              "      <td>0.055421</td>\n",
              "      <td>-1.207686</td>\n",
              "      <td>1.0300</td>\n",
              "      <td>1.6467</td>\n",
              "      <td>0.085000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.291030</td>\n",
              "      <td>1.952326</td>\n",
              "      <td>23.08</td>\n",
              "      <td>40.50</td>\n",
              "      <td>1.596464</td>\n",
              "      <td>28.400</td>\n",
              "      <td>28.379764</td>\n",
              "      <td>1.955008</td>\n",
              "      <td>15.211556</td>\n",
              "      <td>als</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 92 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Elapsed Time(s)Min  Elapsed Time(s)Max  Elapsed Time(s)Std  \\\n",
              "0              21.9300            298.6000           80.541475   \n",
              "1              22.0600            298.7500           80.301624   \n",
              "2              21.6100            299.0567           80.423591   \n",
              "3              21.8933            299.7633           80.529795   \n",
              "4              22.3600            299.4167           80.219752   \n",
              "..                 ...                 ...                 ...   \n",
              "59             21.9533            288.9133           78.506061   \n",
              "60             22.7167            298.4100           80.233487   \n",
              "61             23.5267            299.4433           79.445782   \n",
              "62             22.8900            299.0233           80.484751   \n",
              "63             22.6033            299.0500           80.820757   \n",
              "\n",
              "    Elapsed Time(s)Med  Elapsed Time(s)Avg  Elapsed Time(s)Skewness  \\\n",
              "0            159.63670          159.676873                 0.007791   \n",
              "1            159.92330          160.034960                 0.003471   \n",
              "2            160.76000          160.275018                -0.002409   \n",
              "3            160.14830          160.156720                 0.005247   \n",
              "4            159.71000          160.227956                 0.012561   \n",
              "..                 ...                 ...                      ...   \n",
              "59           153.10330          156.746292                -0.003560   \n",
              "60           161.48835          160.529298                 0.003958   \n",
              "61           159.00000          160.555286                 0.022279   \n",
              "62           158.15335          159.315691                 0.026569   \n",
              "63           154.89500          156.945927                 0.055421   \n",
              "\n",
              "    Elapsed Time(s)Kurtosis  Left Stride Interval(s)Min  \\\n",
              "0                 -1.205423                      0.9633   \n",
              "1                 -1.199675                      0.9300   \n",
              "2                 -1.202074                      0.9667   \n",
              "3                 -1.193897                      1.0033   \n",
              "4                 -1.190490                      1.0300   \n",
              "..                      ...                         ...   \n",
              "59                -1.239587                      1.1733   \n",
              "60                -1.201741                      1.4233   \n",
              "61                -1.179486                      1.5067   \n",
              "62                -1.205942                      1.0567   \n",
              "63                -1.207686                      1.0300   \n",
              "\n",
              "    Left Stride Interval(s)Max  Left Stride Interval(s)Std  ...  \\\n",
              "0                       1.3967                    0.040895  ...   \n",
              "1                       1.3533                    0.041952  ...   \n",
              "2                       1.3767                    0.036877  ...   \n",
              "3                       2.0233                    0.074304  ...   \n",
              "4                       1.2967                    0.038959  ...   \n",
              "..                         ...                         ...  ...   \n",
              "59                      9.1833                    0.561663  ...   \n",
              "60                      2.1700                    0.102321  ...   \n",
              "61                      2.2733                    0.129713  ...   \n",
              "62                      1.6533                    0.073385  ...   \n",
              "63                      1.6467                    0.085000  ...   \n",
              "\n",
              "    Double Support Interval(s)Skewness  Double Support Interval(s)Kurtosis  \\\n",
              "0                             1.846643                            7.133888   \n",
              "1                             6.941808                           70.516428   \n",
              "2                             3.291091                           18.503456   \n",
              "3                             9.383892                          109.145808   \n",
              "4                             2.858954                           16.734192   \n",
              "..                                 ...                                 ...   \n",
              "59                            5.154047                           49.777404   \n",
              "60                            3.286439                           16.668301   \n",
              "61                            1.302906                           -0.176652   \n",
              "62                            2.086797                            6.995220   \n",
              "63                            0.291030                            1.952326   \n",
              "\n",
              "    Double Support Interval(%)Min  Double Support Interval(%)Max  \\\n",
              "0                           26.69                          46.03   \n",
              "1                           23.18                          46.80   \n",
              "2                           27.71                          41.74   \n",
              "3                           23.15                          56.67   \n",
              "4                           21.45                          42.16   \n",
              "..                            ...                            ...   \n",
              "59                          25.00                         134.31   \n",
              "60                          35.93                          67.28   \n",
              "61                          23.08                         161.44   \n",
              "62                          23.19                          53.63   \n",
              "63                          23.08                          40.50   \n",
              "\n",
              "    Double Support Interval(%)Std  Double Support Interval(%)Med  \\\n",
              "0                        2.582514                         31.830   \n",
              "1                        1.989210                         26.170   \n",
              "2                        1.920116                         31.310   \n",
              "3                        2.977208                         26.180   \n",
              "4                        2.461296                         25.860   \n",
              "..                            ...                            ...   \n",
              "59                      47.483061                         33.060   \n",
              "60                       4.369722                         43.495   \n",
              "61                      43.788066                         42.910   \n",
              "62                       2.712919                         30.210   \n",
              "63                       1.596464                         28.400   \n",
              "\n",
              "    Double Support Interval(%)Avg  Double Support Interval(%)Skewness  \\\n",
              "0                       32.048185                            1.657463   \n",
              "1                       26.510578                            5.874844   \n",
              "2                       31.494610                            1.796461   \n",
              "3                       26.703115                            5.819219   \n",
              "4                       26.391873                            2.645490   \n",
              "..                            ...                                 ...   \n",
              "59                      73.440439                            0.221811   \n",
              "60                      44.058977                            2.022438   \n",
              "61                      64.953711                            1.311714   \n",
              "62                      30.731422                            3.042503   \n",
              "63                      28.379764                            1.955008   \n",
              "\n",
              "    Double Support Interval(%)Kurtosis    label  \n",
              "0                             6.628575  control  \n",
              "1                            51.107931  control  \n",
              "2                             6.547346  control  \n",
              "3                            47.517179  control  \n",
              "4                            12.970039  control  \n",
              "..                                 ...      ...  \n",
              "59                           -1.928994      als  \n",
              "60                            7.497516      als  \n",
              "61                           -0.198004      als  \n",
              "62                           21.384431      als  \n",
              "63                           15.211556      als  \n",
              "\n",
              "[64 rows x 92 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y96pKUP9pZSK"
      },
      "outputs": [],
      "source": [
        "# Split features and labels\n",
        "X = data.drop('label', axis=1).values\n",
        "y = data['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3k_DiFCpZSK"
      },
      "outputs": [],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HfW2fWCpZSK",
        "outputId": "1f3bf5df-1607-459b-954a-24b96bcaa4fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.19300000e+01,  2.98600000e+02,  8.05414747e+01, ...,\n",
              "         3.20481853e+01,  1.65746346e+00,  6.62857455e+00],\n",
              "       [ 2.20600000e+01,  2.98750000e+02,  8.03016243e+01, ...,\n",
              "         2.65105776e+01,  5.87484359e+00,  5.11079311e+01],\n",
              "       [ 2.16100000e+01,  2.99056700e+02,  8.04235911e+01, ...,\n",
              "         3.14946097e+01,  1.79646051e+00,  6.54734589e+00],\n",
              "       ...,\n",
              "       [ 2.35267000e+01,  2.99443300e+02,  7.94457820e+01, ...,\n",
              "         6.49537107e+01,  1.31171373e+00, -1.98003719e-01],\n",
              "       [ 2.28900000e+01,  2.99023300e+02,  8.04847509e+01, ...,\n",
              "         3.07314224e+01,  3.04250326e+00,  2.13844308e+01],\n",
              "       [ 2.26033000e+01,  2.99050000e+02,  8.08207567e+01, ...,\n",
              "         2.83797642e+01,  1.95500813e+00,  1.52115563e+01]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzlfv5EUpZSL",
        "outputId": "eda62d35-7b33-4615-a88e-8c1a241bf530"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d2F4uq-pZSL"
      },
      "outputs": [],
      "source": [
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQOdwkcDpZSL"
      },
      "outputs": [],
      "source": [
        "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x5vASuwpZSM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd_BQxKLpZSM"
      },
      "source": [
        "Simple LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC6X-PQfpZSO"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(X_reshaped.shape[1], X_reshaped.shape[2])))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2EozWPnpZSO",
        "outputId": "151eebba-cc9d-48b0-ab8b-aaf260f825d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.0813 - loss: 1.3961 - val_accuracy: 0.3636 - val_loss: 1.3709\n",
            "Epoch 2/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2771 - loss: 1.3890 - val_accuracy: 0.5455 - val_loss: 1.3701\n",
            "Epoch 3/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.3958 - loss: 1.3777 - val_accuracy: 0.5455 - val_loss: 1.3689\n",
            "Epoch 4/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4188 - loss: 1.3720 - val_accuracy: 0.5455 - val_loss: 1.3677\n",
            "Epoch 5/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4833 - loss: 1.3672 - val_accuracy: 0.4545 - val_loss: 1.3655\n",
            "Epoch 6/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5167 - loss: 1.3602 - val_accuracy: 0.5455 - val_loss: 1.3632\n",
            "Epoch 7/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5437 - loss: 1.3536 - val_accuracy: 0.5455 - val_loss: 1.3606\n",
            "Epoch 8/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5333 - loss: 1.3439 - val_accuracy: 0.3636 - val_loss: 1.3577\n",
            "Epoch 9/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5437 - loss: 1.3380 - val_accuracy: 0.3636 - val_loss: 1.3545\n",
            "Epoch 10/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5813 - loss: 1.3298 - val_accuracy: 0.3636 - val_loss: 1.3510\n",
            "Epoch 11/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5604 - loss: 1.3246 - val_accuracy: 0.3636 - val_loss: 1.3470\n",
            "Epoch 12/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5813 - loss: 1.3099 - val_accuracy: 0.3636 - val_loss: 1.3417\n",
            "Epoch 13/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5813 - loss: 1.3010 - val_accuracy: 0.3636 - val_loss: 1.3359\n",
            "Epoch 14/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5875 - loss: 1.2932 - val_accuracy: 0.3636 - val_loss: 1.3293\n",
            "Epoch 15/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5646 - loss: 1.2795 - val_accuracy: 0.3636 - val_loss: 1.3216\n",
            "Epoch 16/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5708 - loss: 1.2657 - val_accuracy: 0.3636 - val_loss: 1.3135\n",
            "Epoch 17/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5875 - loss: 1.2486 - val_accuracy: 0.3636 - val_loss: 1.3047\n",
            "Epoch 18/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6250 - loss: 1.2349 - val_accuracy: 0.3636 - val_loss: 1.2950\n",
            "Epoch 19/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6458 - loss: 1.2120 - val_accuracy: 0.3636 - val_loss: 1.2843\n",
            "Epoch 20/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6521 - loss: 1.1851 - val_accuracy: 0.3636 - val_loss: 1.2737\n",
            "Epoch 21/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6896 - loss: 1.1798 - val_accuracy: 0.4545 - val_loss: 1.2619\n",
            "Epoch 22/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5813 - loss: 1.1398 - val_accuracy: 0.4545 - val_loss: 1.2504\n",
            "Epoch 23/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7063 - loss: 1.1322 - val_accuracy: 0.4545 - val_loss: 1.2390\n",
            "Epoch 24/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6958 - loss: 1.0974 - val_accuracy: 0.4545 - val_loss: 1.2271\n",
            "Epoch 25/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6896 - loss: 1.0768 - val_accuracy: 0.4545 - val_loss: 1.2172\n",
            "Epoch 26/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7271 - loss: 1.0454 - val_accuracy: 0.4545 - val_loss: 1.2082\n",
            "Epoch 27/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7125 - loss: 1.0256 - val_accuracy: 0.4545 - val_loss: 1.1995\n",
            "Epoch 28/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7771 - loss: 1.0014 - val_accuracy: 0.4545 - val_loss: 1.1903\n",
            "Epoch 29/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7604 - loss: 0.9440 - val_accuracy: 0.4545 - val_loss: 1.1808\n",
            "Epoch 30/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8313 - loss: 0.9311 - val_accuracy: 0.4545 - val_loss: 1.1727\n",
            "Epoch 31/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7438 - loss: 0.9132 - val_accuracy: 0.4545 - val_loss: 1.1646\n",
            "Epoch 32/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.7500 - loss: 0.8893 - val_accuracy: 0.4545 - val_loss: 1.1567\n",
            "Epoch 33/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7667 - loss: 0.8647 - val_accuracy: 0.5455 - val_loss: 1.1482\n",
            "Epoch 34/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.8208 - loss: 0.8327 - val_accuracy: 0.5455 - val_loss: 1.1411\n",
            "Epoch 35/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7937 - loss: 0.7903 - val_accuracy: 0.6364 - val_loss: 1.1362\n",
            "Epoch 36/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8104 - loss: 0.7893 - val_accuracy: 0.6364 - val_loss: 1.1321\n",
            "Epoch 37/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7937 - loss: 0.7734 - val_accuracy: 0.6364 - val_loss: 1.1293\n",
            "Epoch 38/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8313 - loss: 0.7123 - val_accuracy: 0.6364 - val_loss: 1.1287\n",
            "Epoch 39/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.8417 - loss: 0.6931 - val_accuracy: 0.6364 - val_loss: 1.1289\n",
            "Epoch 40/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8146 - loss: 0.6519 - val_accuracy: 0.6364 - val_loss: 1.1283\n",
            "Epoch 41/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8104 - loss: 0.6781 - val_accuracy: 0.6364 - val_loss: 1.1246\n",
            "Epoch 42/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8313 - loss: 0.6113 - val_accuracy: 0.5455 - val_loss: 1.1230\n",
            "Epoch 43/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8750 - loss: 0.5960 - val_accuracy: 0.5455 - val_loss: 1.1267\n",
            "Epoch 44/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8646 - loss: 0.5619 - val_accuracy: 0.5455 - val_loss: 1.1317\n",
            "Epoch 45/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8750 - loss: 0.5434 - val_accuracy: 0.5455 - val_loss: 1.1358\n",
            "Epoch 46/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8854 - loss: 0.4909 - val_accuracy: 0.5455 - val_loss: 1.1428\n",
            "Epoch 47/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8479 - loss: 0.4708 - val_accuracy: 0.5455 - val_loss: 1.1503\n",
            "Epoch 48/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8750 - loss: 0.4713 - val_accuracy: 0.5455 - val_loss: 1.1557\n",
            "Epoch 49/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8750 - loss: 0.4520 - val_accuracy: 0.5455 - val_loss: 1.1570\n",
            "Epoch 50/50\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8750 - loss: 0.4393 - val_accuracy: 0.5455 - val_loss: 1.1513\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2L9wgmcpZSO",
        "outputId": "5e5f8d8a-3c90-4f4c-ea63-a2d1080efa9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5385 - loss: 1.2280\n",
            "Test Accuracy: 0.5384615659713745\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsEpSfGppZSP"
      },
      "source": [
        "Batch Normalisation (Enhanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGwcqvdnpZSP"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(X_reshaped.shape[1], X_reshaped.shape[2])))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GfMqycppZSP",
        "outputId": "0744b588-a03b-4ec9-fcb1-bb18eefbfe18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.1688 - loss: 2.0494 - val_accuracy: 0.0909 - val_loss: 1.3895\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3542 - loss: 1.4183 - val_accuracy: 0.1818 - val_loss: 1.3890\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4188 - loss: 1.2628 - val_accuracy: 0.1818 - val_loss: 1.3879\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4833 - loss: 1.0897 - val_accuracy: 0.1818 - val_loss: 1.3869\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6521 - loss: 0.8936 - val_accuracy: 0.1818 - val_loss: 1.3859\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6729 - loss: 0.8788 - val_accuracy: 0.1818 - val_loss: 1.3849\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6958 - loss: 0.6310 - val_accuracy: 0.1818 - val_loss: 1.3841\n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9021 - loss: 0.5429 - val_accuracy: 0.1818 - val_loss: 1.3836\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.8146 - loss: 0.5967 - val_accuracy: 0.1818 - val_loss: 1.3834\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7875 - loss: 0.4892 - val_accuracy: 0.1818 - val_loss: 1.3842\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8854 - loss: 0.5152 - val_accuracy: 0.1818 - val_loss: 1.3852\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8479 - loss: 0.4854 - val_accuracy: 0.1818 - val_loss: 1.3857\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8688 - loss: 0.4547 - val_accuracy: 0.1818 - val_loss: 1.3856\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8479 - loss: 0.4724 - val_accuracy: 0.1818 - val_loss: 1.3855\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8750 - loss: 0.3706 - val_accuracy: 0.1818 - val_loss: 1.3846\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8375 - loss: 0.4135 - val_accuracy: 0.1818 - val_loss: 1.3834\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8646 - loss: 0.4113 - val_accuracy: 0.1818 - val_loss: 1.3817\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9229 - loss: 0.3687 - val_accuracy: 0.1818 - val_loss: 1.3792\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8854 - loss: 0.4136 - val_accuracy: 0.1818 - val_loss: 1.3766\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.9396 - loss: 0.2646 - val_accuracy: 0.1818 - val_loss: 1.3740\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9729 - loss: 0.2325 - val_accuracy: 0.1818 - val_loss: 1.3713\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9125 - loss: 0.2592 - val_accuracy: 0.1818 - val_loss: 1.3687\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9125 - loss: 0.3514 - val_accuracy: 0.1818 - val_loss: 1.3664\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.9563 - loss: 0.2403 - val_accuracy: 0.1818 - val_loss: 1.3657\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9458 - loss: 0.1872 - val_accuracy: 0.1818 - val_loss: 1.3654\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9125 - loss: 0.2435 - val_accuracy: 0.1818 - val_loss: 1.3652\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9833 - loss: 0.2042 - val_accuracy: 0.1818 - val_loss: 1.3643\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9729 - loss: 0.2237 - val_accuracy: 0.1818 - val_loss: 1.3642\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9396 - loss: 0.2622 - val_accuracy: 0.1818 - val_loss: 1.3655\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9563 - loss: 0.1964 - val_accuracy: 0.1818 - val_loss: 1.3678\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9292 - loss: 0.2595 - val_accuracy: 0.1818 - val_loss: 1.3697\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9563 - loss: 0.1862 - val_accuracy: 0.1818 - val_loss: 1.3706\n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9729 - loss: 0.1687 - val_accuracy: 0.1818 - val_loss: 1.3703\n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.1273 - val_accuracy: 0.1818 - val_loss: 1.3694\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9667 - loss: 0.1815 - val_accuracy: 0.1818 - val_loss: 1.3680\n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.1128 - val_accuracy: 0.1818 - val_loss: 1.3658\n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9396 - loss: 0.1625 - val_accuracy: 0.1818 - val_loss: 1.3630\n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9833 - loss: 0.1289 - val_accuracy: 0.1818 - val_loss: 1.3595\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0957 - val_accuracy: 0.1818 - val_loss: 1.3564\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9396 - loss: 0.1399 - val_accuracy: 0.1818 - val_loss: 1.3526\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9563 - loss: 0.1396 - val_accuracy: 0.1818 - val_loss: 1.3487\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9833 - loss: 0.1498 - val_accuracy: 0.1818 - val_loss: 1.3460\n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0769 - val_accuracy: 0.1818 - val_loss: 1.3461\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9667 - loss: 0.1538 - val_accuracy: 0.1818 - val_loss: 1.3455\n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0964 - val_accuracy: 0.1818 - val_loss: 1.3451\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9563 - loss: 0.1439 - val_accuracy: 0.1818 - val_loss: 1.3436\n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0786 - val_accuracy: 0.1818 - val_loss: 1.3410\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9292 - loss: 0.1553 - val_accuracy: 0.1818 - val_loss: 1.3392\n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0857 - val_accuracy: 0.1818 - val_loss: 1.3374\n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9833 - loss: 0.0844 - val_accuracy: 0.1818 - val_loss: 1.3371\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0759 - val_accuracy: 0.1818 - val_loss: 1.3365\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9396 - loss: 0.1273 - val_accuracy: 0.1818 - val_loss: 1.3358\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9729 - loss: 0.1082 - val_accuracy: 0.1818 - val_loss: 1.3333\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0761 - val_accuracy: 0.1818 - val_loss: 1.3307\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0701 - val_accuracy: 0.1818 - val_loss: 1.3281\n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0546 - val_accuracy: 0.1818 - val_loss: 1.3264\n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9729 - loss: 0.0818 - val_accuracy: 0.1818 - val_loss: 1.3234\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0774 - val_accuracy: 0.1818 - val_loss: 1.3208\n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9563 - loss: 0.1141 - val_accuracy: 0.1818 - val_loss: 1.3202\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0563 - val_accuracy: 0.1818 - val_loss: 1.3221\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9729 - loss: 0.0769 - val_accuracy: 0.1818 - val_loss: 1.3217\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0341 - val_accuracy: 0.1818 - val_loss: 1.3187\n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0769 - val_accuracy: 0.1818 - val_loss: 1.3157\n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9833 - loss: 0.0849 - val_accuracy: 0.1818 - val_loss: 1.3115\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0591 - val_accuracy: 0.1818 - val_loss: 1.3054\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9833 - loss: 0.0705 - val_accuracy: 0.1818 - val_loss: 1.2986\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0307 - val_accuracy: 0.1818 - val_loss: 1.2928\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9833 - loss: 0.0836 - val_accuracy: 0.1818 - val_loss: 1.2865\n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.9729 - loss: 0.0508 - val_accuracy: 0.2727 - val_loss: 1.2803\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9729 - loss: 0.0575 - val_accuracy: 0.2727 - val_loss: 1.2754\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9667 - loss: 0.1235 - val_accuracy: 0.2727 - val_loss: 1.2723\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0444 - val_accuracy: 0.3636 - val_loss: 1.2684\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9729 - loss: 0.0994 - val_accuracy: 0.2727 - val_loss: 1.2686\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9729 - loss: 0.0675 - val_accuracy: 0.2727 - val_loss: 1.2707\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0520 - val_accuracy: 0.2727 - val_loss: 1.2727\n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0564 - val_accuracy: 0.2727 - val_loss: 1.2779\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9833 - loss: 0.0878 - val_accuracy: 0.2727 - val_loss: 1.2829\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0442 - val_accuracy: 0.2727 - val_loss: 1.2847\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0558 - val_accuracy: 0.3636 - val_loss: 1.2875\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9833 - loss: 0.0577 - val_accuracy: 0.3636 - val_loss: 1.2889\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0450 - val_accuracy: 0.3636 - val_loss: 1.2889\n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9729 - loss: 0.0810 - val_accuracy: 0.3636 - val_loss: 1.2870\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.3636 - val_loss: 1.2844\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9729 - loss: 0.0776 - val_accuracy: 0.3636 - val_loss: 1.2782\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0447 - val_accuracy: 0.3636 - val_loss: 1.2648\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0651 - val_accuracy: 0.3636 - val_loss: 1.2524\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0374 - val_accuracy: 0.3636 - val_loss: 1.2427\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9833 - loss: 0.0540 - val_accuracy: 0.3636 - val_loss: 1.2363\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.3636 - val_loss: 1.2326\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0255 - val_accuracy: 0.3636 - val_loss: 1.2304\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0353 - val_accuracy: 0.3636 - val_loss: 1.2308\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9833 - loss: 0.0562 - val_accuracy: 0.3636 - val_loss: 1.2320\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.3636 - val_loss: 1.2365\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0309 - val_accuracy: 0.3636 - val_loss: 1.2408\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9729 - loss: 0.0555 - val_accuracy: 0.3636 - val_loss: 1.2499\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9833 - loss: 0.0463 - val_accuracy: 0.3636 - val_loss: 1.2508\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9729 - loss: 0.0433 - val_accuracy: 0.3636 - val_loss: 1.2513\n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9833 - loss: 0.0420 - val_accuracy: 0.3636 - val_loss: 1.2577\n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.3636 - val_loss: 1.2668\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.3636 - val_loss: 1.2785\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_FnUF3RpZSQ",
        "outputId": "378786cd-366d-4fbc-c8cc-d626a59735db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4615 - loss: 1.2230\n",
            "Test Accuracy: 0.4615384638309479\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PBQR3fopZSQ"
      },
      "source": [
        "Early Stopping and Class Weights?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6knr-WF3pZSQ"
      },
      "outputs": [],
      "source": [
        "# Compute class weights to handle imbalanced data\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_encoded), y=y_encoded)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po3IjEdapZSR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# %%\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X_reshaped.shape[1], X_reshaped.shape[2])))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI08BpVfpZSR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffcoyb8WpZSR",
        "outputId": "c633b42b-7c34-4aad-d693-c008e1501737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 995ms/step - accuracy: 0.1521 - loss: 1.9951 - val_accuracy: 0.1818 - val_loss: 1.3850 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5104 - loss: 1.2400 - val_accuracy: 0.2727 - val_loss: 1.3798 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.4354 - loss: 1.1731 - val_accuracy: 0.1818 - val_loss: 1.3766 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5875 - loss: 0.9406 - val_accuracy: 0.1818 - val_loss: 1.3742 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7229 - loss: 0.7030 - val_accuracy: 0.1818 - val_loss: 1.3710 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7708 - loss: 0.6324 - val_accuracy: 0.2727 - val_loss: 1.3680 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.8250 - loss: 0.6194 - val_accuracy: 0.2727 - val_loss: 1.3648 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7604 - loss: 0.5838 - val_accuracy: 0.2727 - val_loss: 1.3627 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8854 - loss: 0.4439 - val_accuracy: 0.2727 - val_loss: 1.3614 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7833 - loss: 0.5222 - val_accuracy: 0.2727 - val_loss: 1.3599 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8583 - loss: 0.4160 - val_accuracy: 0.2727 - val_loss: 1.3580 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8583 - loss: 0.4022 - val_accuracy: 0.2727 - val_loss: 1.3562 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7438 - loss: 0.5911 - val_accuracy: 0.2727 - val_loss: 1.3541 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8854 - loss: 0.3590 - val_accuracy: 0.2727 - val_loss: 1.3517 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9833 - loss: 0.2746 - val_accuracy: 0.3636 - val_loss: 1.3490 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.9458 - loss: 0.2636 - val_accuracy: 0.4545 - val_loss: 1.3460 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.8479 - loss: 0.3564 - val_accuracy: 0.4545 - val_loss: 1.3432 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9125 - loss: 0.3183 - val_accuracy: 0.4545 - val_loss: 1.3399 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9833 - loss: 0.2615 - val_accuracy: 0.4545 - val_loss: 1.3368 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.8917 - loss: 0.3568 - val_accuracy: 0.4545 - val_loss: 1.3343 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.9729 - loss: 0.2153 - val_accuracy: 0.4545 - val_loss: 1.3314 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9396 - loss: 0.1921 - val_accuracy: 0.4545 - val_loss: 1.3285 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9563 - loss: 0.1661 - val_accuracy: 0.4545 - val_loss: 1.3253 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.9292 - loss: 0.2701 - val_accuracy: 0.4545 - val_loss: 1.3224 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9563 - loss: 0.2813 - val_accuracy: 0.3636 - val_loss: 1.3202 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9667 - loss: 0.1731 - val_accuracy: 0.3636 - val_loss: 1.3188 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9500 - loss: 0.2419 - val_accuracy: 0.3636 - val_loss: 1.3169 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9833 - loss: 0.1696 - val_accuracy: 0.4545 - val_loss: 1.3161 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.9396 - loss: 0.2567 - val_accuracy: 0.3636 - val_loss: 1.3173 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.9833 - loss: 0.1682 - val_accuracy: 0.3636 - val_loss: 1.3192 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.9729 - loss: 0.1512 - val_accuracy: 0.3636 - val_loss: 1.3212 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9500 - loss: 0.2120 - val_accuracy: 0.3636 - val_loss: 1.3219 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9396 - loss: 0.1834 - val_accuracy: 0.3636 - val_loss: 1.3215 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9563 - loss: 0.1678 - val_accuracy: 0.3636 - val_loss: 1.3203 - learning_rate: 2.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9833 - loss: 0.1370 - val_accuracy: 0.3636 - val_loss: 1.3190 - learning_rate: 2.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9563 - loss: 0.1780 - val_accuracy: 0.3636 - val_loss: 1.3175 - learning_rate: 2.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9667 - loss: 0.1575 - val_accuracy: 0.3636 - val_loss: 1.3161 - learning_rate: 2.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9563 - loss: 0.1580 - val_accuracy: 0.2727 - val_loss: 1.3144 - learning_rate: 2.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9187 - loss: 0.1890 - val_accuracy: 0.2727 - val_loss: 1.3122 - learning_rate: 2.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9833 - loss: 0.1152 - val_accuracy: 0.2727 - val_loss: 1.3102 - learning_rate: 2.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9833 - loss: 0.1223 - val_accuracy: 0.2727 - val_loss: 1.3077 - learning_rate: 2.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.1353 - val_accuracy: 0.2727 - val_loss: 1.3053 - learning_rate: 2.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9833 - loss: 0.1304 - val_accuracy: 0.2727 - val_loss: 1.3023 - learning_rate: 2.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.1105 - val_accuracy: 0.2727 - val_loss: 1.2995 - learning_rate: 2.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9563 - loss: 0.1604 - val_accuracy: 0.2727 - val_loss: 1.2965 - learning_rate: 2.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9833 - loss: 0.1133 - val_accuracy: 0.2727 - val_loss: 1.2931 - learning_rate: 2.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0999 - val_accuracy: 0.2727 - val_loss: 1.2893 - learning_rate: 2.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9833 - loss: 0.1339 - val_accuracy: 0.2727 - val_loss: 1.2856 - learning_rate: 2.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9833 - loss: 0.1057 - val_accuracy: 0.2727 - val_loss: 1.2821 - learning_rate: 2.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0733 - val_accuracy: 0.2727 - val_loss: 1.2789 - learning_rate: 2.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9729 - loss: 0.1065 - val_accuracy: 0.2727 - val_loss: 1.2758 - learning_rate: 2.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.1266 - val_accuracy: 0.2727 - val_loss: 1.2731 - learning_rate: 2.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9729 - loss: 0.1104 - val_accuracy: 0.2727 - val_loss: 1.2705 - learning_rate: 2.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9458 - loss: 0.1569 - val_accuracy: 0.2727 - val_loss: 1.2676 - learning_rate: 2.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0789 - val_accuracy: 0.2727 - val_loss: 1.2654 - learning_rate: 2.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9667 - loss: 0.1456 - val_accuracy: 0.2727 - val_loss: 1.2631 - learning_rate: 2.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9563 - loss: 0.1349 - val_accuracy: 0.2727 - val_loss: 1.2605 - learning_rate: 2.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0944 - val_accuracy: 0.2727 - val_loss: 1.2579 - learning_rate: 2.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.1368 - val_accuracy: 0.2727 - val_loss: 1.2550 - learning_rate: 2.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9563 - loss: 0.1546 - val_accuracy: 0.3636 - val_loss: 1.2524 - learning_rate: 2.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9500 - loss: 0.1227 - val_accuracy: 0.3636 - val_loss: 1.2497 - learning_rate: 2.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9833 - loss: 0.0969 - val_accuracy: 0.3636 - val_loss: 1.2474 - learning_rate: 2.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9667 - loss: 0.2185 - val_accuracy: 0.3636 - val_loss: 1.2451 - learning_rate: 2.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9833 - loss: 0.0965 - val_accuracy: 0.3636 - val_loss: 1.2435 - learning_rate: 2.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.1107 - val_accuracy: 0.3636 - val_loss: 1.2416 - learning_rate: 2.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9458 - loss: 0.1349 - val_accuracy: 0.3636 - val_loss: 1.2395 - learning_rate: 2.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1206 - val_accuracy: 0.3636 - val_loss: 1.2374 - learning_rate: 2.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.9563 - loss: 0.1411 - val_accuracy: 0.4545 - val_loss: 1.2349 - learning_rate: 2.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.1097 - val_accuracy: 0.4545 - val_loss: 1.2326 - learning_rate: 2.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0841 - val_accuracy: 0.4545 - val_loss: 1.2305 - learning_rate: 2.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0803 - val_accuracy: 0.4545 - val_loss: 1.2277 - learning_rate: 2.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9833 - loss: 0.0957 - val_accuracy: 0.4545 - val_loss: 1.2248 - learning_rate: 2.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0873 - val_accuracy: 0.5455 - val_loss: 1.2215 - learning_rate: 2.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9563 - loss: 0.0850 - val_accuracy: 0.5455 - val_loss: 1.2173 - learning_rate: 2.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9667 - loss: 0.1215 - val_accuracy: 0.5455 - val_loss: 1.2140 - learning_rate: 2.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9667 - loss: 0.1230 - val_accuracy: 0.5455 - val_loss: 1.2121 - learning_rate: 2.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.1002 - val_accuracy: 0.5455 - val_loss: 1.2097 - learning_rate: 2.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0972 - val_accuracy: 0.5455 - val_loss: 1.2075 - learning_rate: 2.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9833 - loss: 0.0878 - val_accuracy: 0.5455 - val_loss: 1.2055 - learning_rate: 2.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9833 - loss: 0.1336 - val_accuracy: 0.5455 - val_loss: 1.2021 - learning_rate: 2.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9729 - loss: 0.0967 - val_accuracy: 0.5455 - val_loss: 1.1993 - learning_rate: 2.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0882 - val_accuracy: 0.5455 - val_loss: 1.1959 - learning_rate: 2.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9833 - loss: 0.0859 - val_accuracy: 0.5455 - val_loss: 1.1935 - learning_rate: 2.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9729 - loss: 0.1016 - val_accuracy: 0.5455 - val_loss: 1.1910 - learning_rate: 2.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9833 - loss: 0.1642 - val_accuracy: 0.5455 - val_loss: 1.1888 - learning_rate: 2.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 0.0563 - val_accuracy: 0.5455 - val_loss: 1.1879 - learning_rate: 2.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.9833 - loss: 0.0945 - val_accuracy: 0.5455 - val_loss: 1.1859 - learning_rate: 2.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.1077 - val_accuracy: 0.5455 - val_loss: 1.1836 - learning_rate: 2.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0817 - val_accuracy: 0.5455 - val_loss: 1.1809 - learning_rate: 2.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0625 - val_accuracy: 0.5455 - val_loss: 1.1788 - learning_rate: 2.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.1119 - val_accuracy: 0.5455 - val_loss: 1.1764 - learning_rate: 2.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9833 - loss: 0.0882 - val_accuracy: 0.5455 - val_loss: 1.1734 - learning_rate: 2.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9833 - loss: 0.0726 - val_accuracy: 0.5455 - val_loss: 1.1698 - learning_rate: 2.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0560 - val_accuracy: 0.5455 - val_loss: 1.1659 - learning_rate: 2.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0755 - val_accuracy: 0.5455 - val_loss: 1.1623 - learning_rate: 2.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9833 - loss: 0.1459 - val_accuracy: 0.5455 - val_loss: 1.1590 - learning_rate: 2.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0697 - val_accuracy: 0.5455 - val_loss: 1.1560 - learning_rate: 2.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0601 - val_accuracy: 0.5455 - val_loss: 1.1531 - learning_rate: 2.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9667 - loss: 0.1545 - val_accuracy: 0.5455 - val_loss: 1.1487 - learning_rate: 2.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0729 - val_accuracy: 0.5455 - val_loss: 1.1427 - learning_rate: 2.0000e-04\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, class_weight=class_weights_dict, callbacks=[reduce_lr, early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFbL5K8DpZSS",
        "outputId": "245d2e17-14bc-443b-9aa8-d3125de50365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4615 - loss: 1.1595\n",
            "Test Accuracy: 0.4615384638309479\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoVVy-bFpZSS"
      },
      "source": [
        "LOOCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2KtnzrtpZST"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSPUZ-lzpZST",
        "outputId": "c90d6c6e-5aec-4c58-f3d2-9eae6ef50a23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 105 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000016B7749B0A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 106 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000016B7C02AEF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# %%\n",
        "# Initialize LOOCV\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "for train_index, test_index in loo.split(X_reshaped):\n",
        "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
        "    y_train, y_test = y_categorical[train_index], y_categorical[test_index]\n",
        "\n",
        "    model = create_model((X_reshaped.shape[1], X_reshaped.shape[2]))\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, class_weight=class_weights_dict, verbose=0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracies.append(accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn7XqXCvpZST",
        "outputId": "98d6006a-7a39-40a4-bf32-f3720eefa94f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average LOOCV Accuracy: 0.5625\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# %%\n",
        "# Calculate and print the average accuracy\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(f'Average LOOCV Accuracy: {average_accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-aSuQPRpZSU"
      },
      "source": [
        "Ensemble LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGOemwv2pZSU"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape, num_classes=4):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))  # Set number of units to num_classes\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8VXzYJxpZSU",
        "outputId": "e689cf9f-4e69-4132-b107-2bcb9eb4365c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000016B6C4E0D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656ms/step\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000016B7742FF40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995ms/step\n"
          ]
        }
      ],
      "source": [
        "# Initialize LOOCV\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# Initialize empty list to store model predictions\n",
        "all_predictions = []\n",
        "\n",
        "# Iterate over LOOCV splits\n",
        "for train_index, test_index in loo.split(X_reshaped):\n",
        "    X_train, X_test = X_reshaped[train_index], X_reshaped[test_index]\n",
        "    y_train, y_test = y_categorical[train_index], y_categorical[test_index]\n",
        "\n",
        "    # Create and train model\n",
        "    model = create_model((X_reshaped.shape[1], X_reshaped.shape[2]), num_classes=4)  # Set num_classes to 4\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "    all_predictions.append(predictions)\n",
        "\n",
        "# Combine predictions from all models\n",
        "ensemble_predictions = np.mean(all_predictions, axis=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts9x_pzYpZSV",
        "outputId": "d6fe1ee5-a5f4-4927-8deb-b9d76d38733a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760ms/step - accuracy: 0.0000e+00 - loss: 1.3676\n",
            "Ensemble Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate ensemble performance\n",
        "ensemble_loss, ensemble_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Ensemble Accuracy: {ensemble_accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTkGTytFpZSd"
      },
      "source": [
        "CNNLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdkhoSQgpZSd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define a function to create the LSTM model\n",
        "def create_model(units=64, dropout_rate=0.2, learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_reshaped.shape[1], X_reshaped.shape[2])))\n",
        "    model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVKrwyYKpZSd",
        "outputId": "6ace36f1-3bca-42e8-fdca-3cdc9e6f4289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.12.0Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Using cached tensorflow-2.12.0-cp310-cp310-win_amd64.whl.metadata (2.5 kB)\n",
            "Collecting tensorflow-intel==2.12.0 (from tensorflow==2.12.0)\n",
            "  Using cached tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.10.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.28)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.25.3)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.37.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.3.2)\n",
            "Requirement already satisfied: scipy>=1.9 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.29.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.3.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2022.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.2.2)\n",
            "Using cached tensorflow-2.12.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
            "Downloading tensorflow_intel-2.12.0-cp310-cp310-win_amd64.whl (272.8 MB)\n",
            "   -------------------------------------- 272.8/272.8 MB 297.1 kB/s eta 0:00:00\n",
            "Installing collected packages: tensorflow-intel, tensorflow\n",
            "  Attempting uninstall: tensorflow-intel\n",
            "    Found existing installation: tensorflow-intel 2.16.1\n",
            "    Uninstalling tensorflow-intel-2.16.1:\n",
            "      Successfully uninstalled tensorflow-intel-2.16.1\n",
            "  Rolling back uninstall of tensorflow-intel\n",
            "  Moving to c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\scripts\\import_pb_to_tensorboard.exe\n",
            "   from C:\\Users\\Sanju\\AppData\\Local\\Temp\\pip-uninstall-9h0yvfm5\\import_pb_to_tensorboard.exe\n",
            "  Moving to c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\scripts\\saved_model_cli.exe\n",
            "   from C:\\Users\\Sanju\\AppData\\Local\\Temp\\pip-uninstall-9h0yvfm5\\saved_model_cli.exe\n",
            "  Moving to c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\scripts\\tensorboard.exe\n",
            "   from C:\\Users\\Sanju\\AppData\\Local\\Temp\\pip-uninstall-9h0yvfm5\\tensorboard.exe\n",
            "  Moving to c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\scripts\\tf_upgrade_v2.exe\n",
            "   from C:\\Users\\Sanju\\AppData\\Local\\Temp\\pip-uninstall-9h0yvfm5\\tf_upgrade_v2.exe\n",
            "  Moving to c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\scripts\\tflite_convert.exe\n",
            "   from C:\\Users\\Sanju\\AppData\\Local\\Temp\\pip-uninstall-9h0yvfm5\\tflite_convert.exe\n",
            "  Moving to c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\scripts\\toco.exe\n",
            "   from C:\\Users\\Sanju\\AppData\\Local\\Temp\\pip-uninstall-9h0yvfm5\\toco.exe\n",
            "  Moving to c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\scripts\\toco_from_protos.exe\n",
            "   from C:\\Users\\Sanju\\AppData\\Local\\Temp\\pip-uninstall-9h0yvfm5\\toco_from_protos.exe\n",
            "  Moving to c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages\\tensorflow\\\n",
            "   from C:\\Users\\Sanju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\~ensorflow\n",
            "  Moving to c:\\users\\sanju\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages\\tensorflow_intel-2.16.1.dist-info\\\n",
            "   from C:\\Users\\Sanju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\~ensorflow_intel-2.16.1.dist-info\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow==2.12.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeMD12qspZSd",
        "outputId": "9009b38f-ba7b-4cc7-e14f-efd203aa1968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Sanju\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\losses.py:2664: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomizedSearchCV\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\api\\_v2\\keras\\__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\models\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\functional.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py:40\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pickle_utils\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_api\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\saving\\saving_api.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save \u001b[38;5;28;01mas\u001b[39;00m legacy_sm_saving_lib\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\saving\\legacy\\save.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load \u001b[38;5;28;01mas\u001b[39;00m saved_model_load\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_context\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save \u001b[38;5;28;01mas\u001b[39;00m saved_model_save\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_option_scope\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\saving\\legacy\\saved_model\\load_context.py:68\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether under a load context.\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_context\u001b[38;5;241m.\u001b[39min_load_context()\n\u001b[1;32m---> 68\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_load_context_function\u001b[49m(in_load_context)\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr2l6d94pZSe",
        "outputId": "7437e5bc-8873-4a8b-bf5f-db38d19e0458"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow.keras.wrappers'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomizedSearchCV\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx4j3oOCpZSe",
        "outputId": "2b0ef209-5972-4f54-8128-9e9a81907470"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'KerasClassifier' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create KerasClassifier for use in RandomizedSearchCV\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mKerasClassifier\u001b[49m(build_fn\u001b[38;5;241m=\u001b[39mcreate_model, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define the hyperparameter grid\u001b[39;00m\n\u001b[0;32m      5\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m],\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m]\n\u001b[0;32m      9\u001b[0m }\n",
            "\u001b[1;31mNameError\u001b[0m: name 'KerasClassifier' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create KerasClassifier for use in RandomizedSearchCV\n",
        "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'units': [64, 128, 256],\n",
        "    'dropout_rate': [0.2, 0.3, 0.4],\n",
        "    'learning_rate': [0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "# Perform random search\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=3, verbose=2)\n",
        "random_search_result = random_search.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDDf5dd1pZSe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", random_search_result.best_params_)\n",
        "print(\"Best Score:\", random_search_result.best_score_)\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model = random_search_result.best_estimator_\n",
        "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# Plotting training history\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmhBmZY8pZSf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting training history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
